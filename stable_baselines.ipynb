{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/GIDISIA/RLDiplodatos/blob/master/stable_baselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SytTR8K1oII-"
   },
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BFrF74foIJD"
   },
   "source": [
    "Créditos:\n",
    "\n",
    "* Documentación y repo de Stable-baselines https://stable-baselines3.readthedocs.io.\n",
    "    * Tutorial sobre SB3: https://github.com/araffin/rl-tutorial-jnrr19.\n",
    "* Documentación y repo de OpenAI Gym https://github.com/openai/gym/blob/master/docs/.\n",
    "    * Crear un entorno https://github.com/openai/gym/blob/master/docs/creating-environments.md. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlZ0ehGZoIJD"
   },
   "source": [
    "Stable-baselines3: framework de deep RL que provee interfaces para ejecutar y adaptar algoritmos de RL \"al estilo scikit-learn\". Permite utilizar agentes abstrayéndonos de los detalles de bajo nivel de abstracción referentes a la implementación del algoritmo$^1$\n",
    "\n",
    "Además, ofrece herramientas muy útiles como\n",
    "\n",
    "* Monitores que permiten ver el rendimiento del agente según se desempeña en el entorno, sin tener que esperar a que finalice de entrenar.\n",
    "* Callbacks que permiten accionar eventos cuando se cumplen algunas condiciones en el entrenamiento de nuestro agente (por ejemplo, detenerlo si la recompensa recibida es menor a cierto umbral tras un cierto período de tiempo).\n",
    "\n",
    "\n",
    "Documentación https://stable-baselines3.readthedocs.io\n",
    "\n",
    "Es un fork activamente mantenido de [OpenAI baselines](https://github.com/openai/baselines)\n",
    "\n",
    "La versión 3 cambia el framework subyacente de Tensorflow a Pytorch y está activamente en desarrollo; no obstante la versión 2 es completamente funcional\n",
    "\n",
    "$^1$ no obstante, al igual que sucede generalmente con librerías de ML: \n",
    "\n",
    "* Siempre es bueno tener en mente las características, ventajas y desventajas del algoritmo utilizado, pues de eso depende mucho la convergencia de nuestra solución, especialmente cuando se emplean entornos adaptados para nuestras necesidades. \n",
    "\n",
    "* Esta librería, al igual que demás frameworks generales de RL, están muy probadas en entornos estándares de RL como Atari o PyBullet. No obstante, es posible que nuestro entorno o nuestras necesidades difieran significativamente, lo que hace que en algunos casos haya que meter mano directo en el código de los algoritmos/librería."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4SWX4wuoIJE"
   },
   "source": [
    "# Interfaz básica stable-baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SD-FSSuKoIJF"
   },
   "source": [
    "### Instalación de Stable-baselines\n",
    "\n",
    "Desde Linux o Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ttqOLol_oIJG",
    "outputId": "e7b26d16-a6d3-45af-ca5f-332a2330427a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sb3-contrib in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (0.11.0a5)\n",
      "Requirement already satisfied: stable-baselines3[docs,tests]>=0.11.0a2 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from sb3-contrib) (0.11.0a4)\n",
      "Requirement already satisfied: gym>=0.17 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (0.18.0)\n",
      "Requirement already satisfied: numpy in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.19.5)\n",
      "Requirement already satisfied: cloudpickle in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.6.0)\n",
      "Requirement already satisfied: pandas in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.2.1)\n",
      "Requirement already satisfied: matplotlib in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (3.3.4)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.7.1)\n",
      "Requirement already satisfied: pytest-env in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (0.6.2)\n",
      "Requirement already satisfied: pytest-xdist in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2.2.0)\n",
      "Requirement already satisfied: pytype in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2021.1.28)\n",
      "Requirement already satisfied: black in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (20.8b1)\n",
      "Requirement already satisfied: pytest-cov in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2.11.1)\n",
      "Requirement already satisfied: flake8>=3.8 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (3.8.4)\n",
      "Requirement already satisfied: pytest in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (6.2.2)\n",
      "Requirement already satisfied: isort>=5.0 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (5.7.0)\n",
      "Requirement already satisfied: sphinx in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (3.4.3)\n",
      "Requirement already satisfied: sphinx-autodoc-typehints in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.11.1)\n",
      "Requirement already satisfied: sphinxcontrib.spelling in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (7.1.0)\n",
      "Requirement already satisfied: sphinx-autobuild in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2020.9.1)\n",
      "Requirement already satisfied: sphinx-rtd-theme in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (0.5.1)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from flake8>=3.8->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (0.6.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from flake8>=3.8->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (3.4.0)\n",
      "Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from flake8>=3.8->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2.2.0)\n",
      "Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from flake8>=3.8->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2.6.0)\n",
      "Requirement already satisfied: typing-extensions in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from torch>=1.4.0->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (3.7.4.3)\n",
      "Requirement already satisfied: appdirs in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from black->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.4.4)\n",
      "Requirement already satisfied: toml>=0.10.1 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from black->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (0.10.2)\n",
      "Requirement already satisfied: typed-ast>=1.4.0 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from black->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.4.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from black->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (0.4.3)\n",
      "Requirement already satisfied: pathspec<1,>=0.6 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from black->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (0.8.1)\n",
      "Requirement already satisfied: regex>=2020.1.8 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from black->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2020.11.13)\n",
      "Requirement already satisfied: click>=7.1.2 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from black->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (7.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from importlib-metadata->flake8>=3.8->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (3.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from matplotlib->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from matplotlib->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from matplotlib->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (8.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from matplotlib->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from matplotlib->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2.8.1)\n",
      "Requirement already satisfied: six in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from pandas->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2021.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from pytest->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.10.0)\n",
      "Requirement already satisfied: packaging in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from pytest->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (20.9)\n",
      "Requirement already satisfied: iniconfig in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from pytest->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.1.1)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from pytest->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (0.13.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from pytest->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (20.3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: coverage>=5.2.1 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from pytest-cov->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (5.4)\n",
      "Requirement already satisfied: pytest-forked in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from pytest-xdist->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.3.0)\n",
      "Requirement already satisfied: execnet>=1.1 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from pytest-xdist->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.8.0)\n",
      "Requirement already satisfied: apipkg>=1.4 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from execnet>=1.1->pytest-xdist->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.5)\n",
      "Requirement already satisfied: pyyaml>=3.11 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from pytype->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (5.4.1)\n",
      "Requirement already satisfied: importlab>=0.6.1 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from pytype->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (0.6.1)\n",
      "Requirement already satisfied: ninja>=1.10.0.post2 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from pytype->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.10.0.post2)\n",
      "Requirement already satisfied: networkx>=2 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from importlab>=0.6.1->pytype->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2.5)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from networkx>=2->importlab>=0.6.1->pytype->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (4.4.2)\n",
      "Requirement already satisfied: Pygments>=2.0 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2.7.4)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.0.3)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.0.2)\n",
      "Requirement already satisfied: Jinja2>=2.3 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2.11.3)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2.1.0)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.0.2)\n",
      "Requirement already satisfied: docutils>=0.12 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (0.16)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.1.4)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (0.7.12)\n",
      "Requirement already satisfied: imagesize in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.2.0)\n",
      "Requirement already satisfied: requests>=2.5.0 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2.25.1)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.0.3)\n",
      "Requirement already satisfied: babel>=1.3 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (49.6.0.post20210108)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from Jinja2>=2.3->sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.1.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from requests>=2.5.0->sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from requests>=2.5.0->sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (1.26.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from requests>=2.5.0->sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from requests>=2.5.0->sphinx->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2.10)\n",
      "Requirement already satisfied: livereload in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from sphinx-autobuild->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (2.6.3)\n",
      "Requirement already satisfied: tornado in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from livereload->sphinx-autobuild->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (6.1)\n",
      "Requirement already satisfied: PyEnchant>=3.1.1 in /home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages (from sphinxcontrib.spelling->stable-baselines3[docs,tests]>=0.11.0a2->sb3-contrib) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "#@title Instalación (no modificar)\n",
    "!pip install stable-baselines3[extra,tests,docs]>=0.11.0a4 && pip install sb3-contrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPUpOonyoIJH"
   },
   "source": [
    "## Ejecución de un algoritmo de RL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Morjd1dFoIJH"
   },
   "source": [
    "### Importaciones/inicializaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OG7i44kqoIJH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "#from gym.envs.registration import register\n",
    "\n",
    "from stable_baselines3 import DQN, PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "is2ytf-coIJH"
   },
   "source": [
    "### Ejemplo básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8SqFh7noIJI",
    "outputId": "1d56db34-53bd-450a-8fe8-825f7201ffcf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x7f55cce9a350>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# MlpPolicy es una política \"estándar\" que aprende con perceptron multicapa\n",
    "# (es decir sin capas convolucionales o demás variantes),\n",
    "# 2 capas ocultas con 64 neuronas cada una\n",
    "model = DQN('MlpPolicy', env)\n",
    "model.learn(total_timesteps=10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f5JFC7AoIJK"
   },
   "source": [
    "### Renderización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5nIL0TuwoIJK"
   },
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "\n",
    "    obs = env.reset()\n",
    "    for i in range(1000):\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "        if done:\n",
    "          obs = env.reset()\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTtXPFd2oIJK"
   },
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFYyMrvboIJK"
   },
   "source": [
    "#### Ver rendimiento del agente en tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pC1hqla2oIJK",
    "outputId": "77c1b83c-9952-4ee7-b4eb-2c8bfa0d2024"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x7f54ef581cd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "model = DQN('MlpPolicy', env, tensorboard_log='tensorboard/')\n",
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rldIL1u4oIJL"
   },
   "source": [
    "Para verlo en tensorboard (sólo en local), correr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4Db-mCxoIJL"
   },
   "source": [
    "`tensorboard --logdir=tensorboard/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "2AfqEmCWxWFv",
    "outputId": "e2297f30-400f-4480-b04e-90f1b4dc2549"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 16140), started 0:11:10 ago. (Use '!kill 16140' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-dd058f2c8354cc09\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-dd058f2c8354cc09\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2u0_1dk5oIJL"
   },
   "source": [
    "### Monitor\n",
    "\n",
    "Vamos a crear un monitor para loguear nuestro agente en la carpeta logs. Nuestro monitor guardará datos de recompensa (r), duración (l) y tiempo total (t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r7uF7sQdoIJL",
    "outputId": "ea0fb222-58aa-4c18-9c8c-ae97132ee3ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x7f559e8b9110>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "env = Monitor(env, 'logs/')  # reemplazamos env por su monitor\n",
    "\n",
    "model = DQN('MlpPolicy', env, )\n",
    "model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yVVSGjvoIJM"
   },
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47XdjvaSoIJM",
    "outputId": "8eb9dd8d-ca66-4aee-cdbf-bce8a510ecea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1000, episode_reward=9.60 +/- 0.80\n",
      "Episode length: 9.60 +/- 0.80\n",
      "New best mean reward!\n",
      "Eval num_timesteps=2000, episode_reward=9.20 +/- 0.75\n",
      "Episode length: 9.20 +/- 0.75\n",
      "Eval num_timesteps=3000, episode_reward=9.80 +/- 0.75\n",
      "Episode length: 9.80 +/- 0.75\n",
      "New best mean reward!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/envs/test_rldiplodatos/lib/python3.7/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x7f559e8cf110>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "callbacks = []  # lista de callbacks a usar, pueden ser varios\n",
    "\n",
    "# callback para detener entrenamiento al alcanzar recompensa de 9.8\n",
    "# (a fines demostrativos, es una recompensa baja)\n",
    "stop_training_callback = StopTrainingOnRewardThreshold(reward_threshold=9.8)\n",
    "\n",
    "# al crear EvalCallback, se asocia el mismo con stop_training_callback\n",
    "callbacks.append(EvalCallback(env, \n",
    "                              eval_freq=1000,\n",
    "                              callback_on_new_best=stop_training_callback))\n",
    "\n",
    "# la semilla aleatoria hace que las ejecuciones sean estocásticas\n",
    "model = DQN('MlpPolicy', env, seed=42)\n",
    "model.learn(total_timesteps=10000, callback=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCPD7oaNoIJM"
   },
   "source": [
    "### Ejecutar agente RL en múltiples ambientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNiTT2AzoIJM"
   },
   "source": [
    "Esta librería provee una interfaz para ejecutar agentes en varias instancias de un mismo entorno a la vez (*vectorized environments*), de modo tal que se habilite la ejecución paralela y de otras funcionalidades útiles.\n",
    "\n",
    "Para ello, varios de sus algoritmos implementan cambios que consideren la posibilidad de que haya múltiples entornos subyacentes, por ejemplo `step(accion)` cambia a `step(lista_acciones)`, aplicando acciones a todos los entornos, recibiendo ahora múltiples observaciones y recompensas.\n",
    "\n",
    "Otro cambio: se aplica `reset()` automáticamente a cada entorno que llega a un estado final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GGZjjcDoIJN"
   },
   "source": [
    "SB brinda dos formas de utilizar entornos vectorizados:\n",
    "\n",
    "* DummyVecEnv, el cuál consiste en un *wrapper* de varios entornos, los cuáles funcionarán en un sólo hilo. Este wrapper es útil como entrada de algoritmos que requieren los entornos de esta forma, y habilita los procesamientos y operaciones comunes de los entornos vectorizados (ejemplo: el *stacking* de 4 imágenes en entornos de tipo Atari).\n",
    "* SubprocVecEnv, el cuál agrupa varios entornos que serán ejecutados en paralelo. Atención! **Puede comer mucha RAM**\n",
    "\n",
    "Vemos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ovc6JDmYoIJN",
    "outputId": "6f36d2d0-bc4e-4299-b612-58103bc73f6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f559e8b9910>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejemplo de ambiente dummy\n",
    "venv = DummyVecEnv([lambda: gym.make('CartPole-v1')]*4)\n",
    "\n",
    "model = PPO('MlpPolicy', venv, )\n",
    "model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkadM0S1oIJO"
   },
   "source": [
    "También puede hacerse con un una función de SB a tal efecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wez-ZY_IoIJO",
    "outputId": "bc30a171-8081-4b97-ba76-063551b2a200"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f559e86ebd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "venv = make_vec_env(lambda: env, n_envs=4)\n",
    "\n",
    "model = PPO('MlpPolicy', venv, )\n",
    "model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjH4ZQ4NoIJO"
   },
   "source": [
    "### Ejecutar agente con políticas personalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jp_aPhIdoIJO",
    "outputId": "19b3f2a7-2821-4fe9-a749-b32be258aee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Creating environment from the given name 'CartPole-v1'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f559e052e90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos una clase con una red neuronal de 128x128 neuronas\n",
    "\n",
    "model = PPO('MlpPolicy', policy_kwargs=dict(net_arch=[128,128]), env='CartPole-v1', verbose=1).learn(total_timesteps=10000)\n",
    "model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbwkBi87oIJO"
   },
   "source": [
    "Utilizar un entorno personalizado\n",
    "\n",
    "Antes que nada, además de la interfaz que ya vimos de Gym, hay otras nociones que tenemos que tener en cuenta en este contexto:\n",
    "\n",
    "* Los entornos definen un espacio de estados y de acciones, a partir de los cuáles los modelos asumen y respetan la \"forma\" de observaciones y acciones. Por ejemplo, algunos algoritmos están diseñados para espacios de acciones discretos (DQN), continuos (DDPG) o bien poseen implementaciones particulares pueden usarse en ambos (PPO, en el repo de SB3). En cuanto a los espacios, algunos algoritmos asumen explícitamente un espacio discreto (y pequeño), como Q-Learning, mientras que otros como PPO asumen cualquier tipo de espacio.\n",
    "* Los dos tipos más comunes de estados o acciones son los espacios discretos `gym.spaces.Discrete` y los continuos `gym.spaces.Box`.\n",
    "* Los espacios discretos definen un conjunto de $n$ estados/acciones $\\{ 0, 1, \\dots, n-1 \\}$, mientras que los espacios continuos definen un espacio $\\mathbb{R}^d$, de una de las siguientes 4 formas: $[a, b], (-\\infty, b], [a, \\infty), (-\\infty, \\infty)$, en donde $a,b$ son las cotas superior e inferior (de existir).\n",
    "* Ejemplos: un espacio de acciones `Discrete(4)` tiene 4 acciones: $\\{0,1,2,3\\}$; un espacio de estados `Discrete(16)` tiene 16 estados. Un espacio de estados ALTURA, ANCHO, N_CANALES que represente una imagen RGB acotada en $[a=0, b=255]$ se puede crear como\n",
    "\n",
    "`observation_space = spaces.Box(low=0, high=255, shape=(HEIGHT, WIDTH, N_CHANNELS), dtype=np.uint8)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFLZieLNoIJO"
   },
   "source": [
    "Para usar un entorno compatible por esta librería, el mismo tiene que heredar de *gym.Env*. Vemos un ejemplo (crédito: https://colab.research.google.com/github/araffin/rl-tutorial-jnrr19/blob/sb3/5_custom_gym_env.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "str0v6DUoIJO"
   },
   "outputs": [],
   "source": [
    "class GoLeftEnv(gym.Env):\n",
    "  \"\"\"\n",
    "  Ambiente personalizado que sigue la interfaz de gym.\n",
    "  Es un entorno simple en el cuál el agente debe aprender a ir siempre \n",
    "  hacia la derecha.\n",
    "  \"\"\"\n",
    "  # Dado que estamos en colab, no podemos implementar la salida por interfaz \n",
    "  # gráfica ('human' render mode) \n",
    "  metadata = {'render.modes': ['console']}\n",
    "  # Definimos las constantes\n",
    "  LEFT = 0\n",
    "  RIGHT = 1\n",
    "\n",
    "  def __init__(self, grid_size=10):\n",
    "    super(GoLeftEnv, self).__init__()\n",
    "\n",
    "    # Tamaño de la grilla de 1D\n",
    "    self.grid_size = grid_size\n",
    "    # Inicializamos en agente a la izquierda de la grilla\n",
    "    self.agent_pos = grid_size - 1\n",
    "\n",
    "    # Definimos el espacio de acción y observaciones\n",
    "    # Los mismos deben ser objetos gym.spaces\n",
    "    # En este ejemplo usamos dos acciones discretas: izquierda y derecha\n",
    "    n_actions = 2\n",
    "    self.action_space = spaces.Discrete(n_actions)\n",
    "    # La observación será la coordenada donde se encuentra el agente\n",
    "    # puede ser descrita tanto por los espacios Discrete como Box\n",
    "    self.observation_space = spaces.Box(low=0, high=self.grid_size,\n",
    "                                        shape=(1,), dtype=np.float32)\n",
    "\n",
    "  def reset(self):\n",
    "    \"\"\"\n",
    "    Important: the observation must be a numpy array\n",
    "    :return: (np.array) \n",
    "    \"\"\"\n",
    "    # Se inicializa el agente a la derecha de la grilla\n",
    "    self.agent_pos = self.grid_size - 1\n",
    "    # convertimos con astype a float32 (numpy) para hacer más general el agente\n",
    "    # (en caso de que querramos usar acciones continuas)\n",
    "    return np.array([self.agent_pos]).astype(np.float32)\n",
    "\n",
    "  def step(self, action):\n",
    "    if action == self.LEFT:\n",
    "      self.agent_pos -= 1\n",
    "    elif action == self.RIGHT:\n",
    "      self.agent_pos += 1\n",
    "    else:\n",
    "      raise ValueError(\"Received invalid action={} which is not part of the action space\".format(action))\n",
    "\n",
    "    # Evitamos que el agente se salga de los límites de la grilla\n",
    "    self.agent_pos = np.clip(self.agent_pos, 0, self.grid_size)\n",
    "\n",
    "    # Llegó el agente a su estado objetivo (izquierda) de la grilla?\n",
    "    done = bool(self.agent_pos == 0)\n",
    "\n",
    "    # Asignamos recompensa sólo cuando el agente llega a su objetivo\n",
    "    # (recompensa = 0 en todos los demás estados)\n",
    "    reward = 1 if self.agent_pos == 0 else 0\n",
    "\n",
    "    # gym también nos permite devolver información adicional, ej. en atari: \n",
    "    # las vidas restantes del agente (no usaremos esto por ahora)\n",
    "    info = {}\n",
    "\n",
    "    return np.array([self.agent_pos]).astype(np.float32), reward, done, info\n",
    "\n",
    "  def render(self, mode='console'):\n",
    "    if mode != 'console':\n",
    "      raise NotImplementedError()\n",
    "    # en nuestra interfaz de consola, representamos el agente como una cruz, y \n",
    "    # el resto como un punto\n",
    "    print(\".\" * self.agent_pos, end=\"\")\n",
    "    print(\"x\", end=\"\")\n",
    "    print(\".\" * (self.grid_size - self.agent_pos))\n",
    "\n",
    "  def close(self):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "flB9-j1SoIJP",
    "outputId": "67ccb533-c91c-441a-8f85-72346c10e1ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "env = GoLeftEnv(grid_size=10)\n",
    "env = make_vec_env(lambda: env, n_envs=1)\n",
    "\n",
    "model = PPO('MlpPolicy', env, verbose=1).learn(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCQE1QoNoIJQ"
   },
   "source": [
    "Ejercicio: crear tu propio entorno y entrenar un agente RL en el mismo. Analizar la convergencia, resultados con distintas funciones de recompensa e híper-parámetros. \n",
    "\n",
    "\n",
    "Algunas ideas:\n",
    "\n",
    "* Transformar GoLeftEnv en una grilla 2D, añadir paredes / trampas / agua.\n",
    "* Crear un entorno que juegue a algún juego como el ta-te-ti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exel4Gr8oIJQ"
   },
   "source": [
    "# RL-baselines3-zoo\n",
    "\n",
    "Colección de agentes RL y herramientas útiles para ejecutarlos, evaluarlos e incluso hacer videos con ellos. Los agentes de este repo están preparados con la configuración requerida para los distintos tipos de entornos, incluyendo Atari, PyBullet y entornos clásicos, incluyendo configuraciones e híper-parámetros que producen buenas políticas para tales entornos.\n",
    "\n",
    "Esta librería ofrece un muy buen punto de partida para utilizar agentes / entornos personalizados, ya que ofrece una [interfaz](https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/train.py) fácilmente adaptable a nuestras necesidades.\n",
    "\n",
    "Si se usan entornos personalizados con rl-baselines3-zoo, debe tenerse en cuenta que se deben definir todos los híper-parámetros de antemano sea al instanciar el agente o en la carpeta /rl-baselines3-zoo/hyperparams; de lo contrario arrojará error por no encontrar qué híper-parámetro usar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUUkScRxoIJQ"
   },
   "source": [
    "### Instalación de RLBaselinesZoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiKPJUfdoIJQ"
   },
   "source": [
    "Desde Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ZM_pM0mIoIJQ",
    "outputId": "8b3aabec-28d0-4caf-93e7-4f4d6cd8725f"
   },
   "outputs": [],
   "source": [
    "#@title Instalación de RLBaselinesZoo (no modificar)\n",
    "\n",
    "if IN_COLAB:\n",
    "    !git clone --recursive https://github.com/DLR-RM/rl-baselines3-zoo\n",
    "    !cd rl-baselines3-zoo/\n",
    "    !apt-get install swig cmake ffmpeg\n",
    "    !pip install -r /content/rl-baselines3-zoo/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzBEoyPzoIJR"
   },
   "source": [
    "Desde Linux, ejecutando\n",
    "\n",
    "    git clone --recursive https://github.com/DLR-RM/rl-baselines3-zoo\n",
    "    cd rl-baselines3-zoo/\n",
    "    sudo apt-get install swig cmake ffmpeg\n",
    "    pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6TCyu_UoIJR"
   },
   "source": [
    "## Ejecución\n",
    "\n",
    "Los agentes pueden ser llamados desde la consola mediante comandos como\n",
    "\n",
    "`python train.py --algo algo_name --env env_id`\n",
    "\n",
    "Los cuales pueden ser llamados usando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jBLMVxhIoIJR"
   },
   "outputs": [],
   "source": [
    "os.chdir('rl-baselines3-zoo/')\n",
    "\n",
    "args = [\n",
    "    '-n', str(100000),\n",
    "    '--algo', 'ppo',\n",
    "    '--env', 'CartPole-v1'\n",
    "]\n",
    "\n",
    "p = Popen(['python', 'train.py'] + args,\n",
    "                               stdin=PIPE, stdout=PIPE, stderr=PIPE)\n",
    "output, err = p.communicate()\n",
    "rc = p.returncode\n",
    "os.chdir(cwd)\n",
    "assert rc == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40H4hNcqoIJR"
   },
   "source": [
    "Ver en acción el agente entrenado (nota: no disponible en Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "cNija96loIJR"
   },
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    pass  # TODO mostrar el uso del enjoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSfIitK7oIJR"
   },
   "source": [
    "También es posible grabar un video! Ver https://stable-baselines3.readthedocs.io/en/master/guide/examples.html#record-a-video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Phq975BYoIJR"
   },
   "source": [
    "Ver curva de aprendizaje obtenida por el agente desde *utils.plot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Q8EA41oQoIJS"
   },
   "outputs": [],
   "source": [
    "os.chdir('rl-baselines3-zoo/')\n",
    "\n",
    "args = [\n",
    "    'ppo',\n",
    "    'CartPole-v1',\n",
    "    'logs/',\n",
    "    'steps'\n",
    "]\n",
    "\n",
    "p = Popen(['python', '-m', 'scripts.plot_train'] + args, stdout=PIPE)\n",
    "output, err = p.communicate()\n",
    "rc = p.returncode\n",
    "os.chdir(cwd)\n",
    "\n",
    "assert rc == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "__1mgFR0oIJT",
    "outputId": "2c355f37-24ae-4e78-ea4c-ac66d3003c23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Figure(800x200)\\n'\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgrWKJlsoIJT"
   },
   "source": [
    "## Normalización de features y recompensas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIfn3o99oIJT"
   },
   "source": [
    "Stable-Baselines3 tiene predefinidos un conjunto de **wrappers** genericos que pueden utilizarse para preprocesar las observaciones que llegan al agente RL, desacomplando del mismo el prepocesamiento.\n",
    "\n",
    "Entre las funcionalidades disponibles tenemos:\n",
    "* **VecFrameStack**: Se utiliza cuando la observación que percibe el agente es una imagen. Sirve para expandir el espacio de estados apilando N frames de manera conjunta.\n",
    "* **VecNormalize**: Se utiliza para normalizar las observaciónes y/o las recompenzas que percibe el agente a $\\mu=0$ y $\\sigma=1$. También permite cortar valores de observaciones y/o recompensas que excedan un rango establecido. \n",
    "* **VecCheckNan**: Se utiliza para trackear los estados del entorno que generan que los gradientes de la RNN se hagan NaN.\n",
    "* **VecVideoRecorder**: Se utiliza para exportar el funcionamiento de la política aprendida por el agente a un video (MP4).\n",
    "\n",
    "Ademas, se pueden crear **wrappers** personalizados extendiendo la clase **VecEnvWrapper**:\n",
    "\n",
    "```\n",
    "class MiWrapper(VecEnvWrapper):\n",
    "    #TODO\n",
    "```\n",
    "### Ejemplo (VecNormalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VOh1HQCVJNA",
    "outputId": "b9f70740-a806-4978-988d-aa296af53c58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x7f54e1731490>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "env = DummyVecEnv([lambda: env])  # Multiple vectorize environments\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.0, clip_reward=10.0) # Observations and reward normalization\n",
    "\n",
    "model = DQN('MlpPolicy', env)\n",
    "model.learn(total_timesteps=10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWzAHj6qoIJT"
   },
   "source": [
    "## Híper-parámetros\n",
    "\n",
    "RL-Baselines Zoo provee funcionalidad para optimizar los híper-parámetros con la librería [Optuna]( https://github.com/optuna/optuna). En los mismos se incluyen rangos de híper-parámetros que se usaron para optimizar entornos como los de PyBullet, y son fácilmente modificables para adaptarlo a nuestros propios entornos. Para ver cómo se llama a la interfaz de Optuna ver [este código](https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/utils/hyperparams_opt.py).\n",
    "\n",
    "Nota: **Consume muchos recursos!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5YbRAbyoIJT"
   },
   "source": [
    "# Recursos adicionales\n",
    "\n",
    "* [Framework adicional de aprendizaje por refuerzos a gran escala](https://docs.ray.io/en/master/rllib.html)\n",
    "* [Awesome Deep RL](https://github.com/kengz/awesome-deep-rl)\n",
    "* [Comunidad de Bots de RL para Rocket League](https://rlbot.org/)\n",
    "* [Blog de Lilian Weng de Deep RL, robótica y NLP](https://lilianweng.github.io/lil-log/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwXMoJy9oIJT"
   },
   "source": [
    "FIN"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "SD-FSSuKoIJF",
    "uUUkScRxoIJQ"
   ],
   "include_colab_link": true,
   "name": "stable_baselines.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
